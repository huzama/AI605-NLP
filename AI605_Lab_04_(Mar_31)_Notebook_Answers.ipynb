{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI605 Lab 04 (Mar 31) Notebook Answers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Quiz 04 Answers\n",
        "1. False\n",
        "2. True\n",
        "3. False\n",
        "4. 3 + 0 + 2 + 7 = 12\n",
        "5. False"
      ],
      "metadata": {
        "id": "2SwLP3RwsqL2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMCEkQ-ipcc3"
      },
      "outputs": [],
      "source": [
        "# Objective 1: Define start and end probability distributions from LSTM outputs for an MRC model\n",
        "\n",
        "import torch\n",
        "from torch.nn import Linear, Softmax\n",
        "\n",
        "torch.manual_seed(605)\n",
        "\n",
        "batch_size = 2\n",
        "seq_len = 8\n",
        "hidden_size = 32\n",
        "\n",
        "layer = Linear(32, 2)\n",
        "softmax = Softmax(-1)\n",
        "\n",
        "lstm_outputs = torch.randn(batch_size, seq_len, hidden_size)\n",
        "\n",
        "start_logits, end_logits = layer(lstm_outputs).chunk(2, dim=-1)\n",
        "start_prob = softmax(start_logits.squeeze(-1))\n",
        "end_prob = softmax(end_logits.squeeze(-1))\n",
        "assert (start_prob[0, 0] * end_prob[0, 7] - 0.0139).abs() < 0.001 # probability that the answer is the entire sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Objective 2: Be able to compute L1 distance, L2 distance, inner product, cosine similarity, and cosine distance\n",
        "\n",
        "import torch\n",
        "\n",
        "torch.manual_seed(605)\n",
        "\n",
        "hidden_size = 32\n",
        "num_a = 4\n",
        "num_b = 8\n",
        "a = torch.randn(num_a, hidden_size)\n",
        "b = torch.randn(num_b, hidden_size)\n",
        "\n",
        "def cosine_distance(a, b):\n",
        "  return (a / a.norm(dim=1, keepdim=True)) @ (b.T / b.T.norm(dim=0, keepdim=True))\n",
        "\n",
        "assert (cosine_distance(a, b)[0, 0] + 0.3874).abs() < 0.001"
      ],
      "metadata": {
        "id": "J-jb6Ft9uHYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Objective 3: Given a list of documents, be able to define TF-IDF vectors\n",
        "\n",
        "import torch\n",
        "\n",
        "torch.manual_seed(605)\n",
        "\n",
        "num_docs = 32\n",
        "vocab_size = 64\n",
        "\n",
        "# Given\n",
        "documents_tf = (torch.rand(num_docs, vocab_size) * 10).round() # term frequency of documents, in the range of 0 to 10\n",
        "query_tf = (torch.rand(1, vocab_size) * 3).round()\n",
        "\n",
        "# Compute tf-idf\n",
        "df = (documents_tf > 0).float().sum(0)\n",
        "idf = torch.log(torch.tensor(documents_tf.size(0))) - df.log()\n",
        "documents_tfidf = documents_tf * idf.unsqueeze(0)\n",
        "query_tfidf = query_tf * idf.unsqueeze(0)\n",
        "scores = cosine_distance(query_tfidf, documents_tfidf)\n",
        "values, indices = scores.max(dim=1)\n",
        "assert indices[0] == 31"
      ],
      "metadata": {
        "id": "TMIN5sSKvhR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "28A6i6z7wK7k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}