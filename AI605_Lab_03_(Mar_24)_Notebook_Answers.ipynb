{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI605 Lab 03 (Mar 24) Notebook Answers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Quiz 03 Answers\n",
        "\n",
        "1. False\n",
        "2. True\n",
        "3. False\n",
        "4. [5, 0, 2.5]\n",
        "5. 64\n",
        "6. $2n + 1$"
      ],
      "metadata": {
        "id": "F_ZlTbhPRKwj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab 03 Objectives"
      ],
      "metadata": {
        "id": "kjojiICDSMgh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-oxVDCBRFzb"
      },
      "outputs": [],
      "source": [
        "# Objective 1: Be able to implement LSTM in an efficient way\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "  def __init__(self, d):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.linear = nn.Linear(2 * d, 4 * d, bias=True)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.output_size = 2 * d # hidden state and memory state are concatenated\n",
        "  \n",
        "  def forward(self, prev_hidden_tensor, input_tensor):\n",
        "    prev_h, prev_c = prev_hidden_tensor.chunk(2, -1)\n",
        "    tensor = torch.cat([prev_h, input_tensor], dim=-1)\n",
        "    tensor = self.linear(tensor)\n",
        "    input_, forget, output, cand_c = tensor.chunk(4, -1)\n",
        "    input_ = self.sigmoid(input_)\n",
        "    forget = self.sigmoid(forget)\n",
        "    output = self.sigmoid(output)\n",
        "    cand_c = self.tanh(cand_c)\n",
        "    cur_c = input_ * cand_c + forget * prev_c\n",
        "    cur_h = output * self.tanh(cur_c)\n",
        "    return torch.cat([cur_h, cur_c], -1)\n",
        "\n",
        "\n",
        "class RNNLayer(nn.Module):\n",
        "  def __init__(self, rnn_module):\n",
        "    super(RNNLayer, self).__init__()\n",
        "    self.rnn_module = rnn_module\n",
        "    self.output_size = rnn_module.output_size\n",
        "  \n",
        "  def forward(self, input_tensor):\n",
        "    cur_hidden_tensor = torch.zeros(input_tensor.shape[0], self.output_size)\n",
        "    h_list = []\n",
        "    for time_step in range(input_tensor.shape[1]):\n",
        "      cur_input_tensor = input_tensor[:, time_step, :]\n",
        "      cur_hidden_tensor = self.rnn_module(cur_hidden_tensor, cur_input_tensor)\n",
        "      h, c = cur_hidden_tensor.chunk(2, -1)\n",
        "      h_list.append(h)\n",
        "    return torch.stack(h_list, dim=1)\n",
        "\n",
        "batch_size = 4\n",
        "seq_len = 8\n",
        "hidden_size = 16\n",
        "lstm = LSTM(hidden_size)\n",
        "lstm_layer = RNNLayer(lstm)\n",
        "\n",
        "input_tensor = torch.randn(batch_size, seq_len, hidden_size)\n",
        "output_tensor = lstm_layer(input_tensor)\n",
        "assert input_tensor.size() == output_tensor.size()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Objective 2: Verify that the upscaled dropout indeed has the same expected value as no-dropout layer\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.manual_seed(605)\n",
        "\n",
        "p = 0.3\n",
        "bias = 2.1\n",
        "num_examples = 1000\n",
        "dim = 128\n",
        "dropout = nn.Dropout(p)\n",
        "input_ = torch.randn(num_examples, dim) + bias\n",
        "output = dropout(input_)\n",
        "\n",
        "assert (input_.mean()-output.mean()).abs() < 0.01"
      ],
      "metadata": {
        "id": "QL0gJVJPWxxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Objective 3: Create an named entity extractor given BIO tags\n",
        "all_tags = (\"B_person\", \"I_person\", \"B_location\", \"I_location\", \"B_organization\", \"I_organization\", \"O\")\n",
        "text = \"Joe Biden is the president of the United States\"\n",
        "tokens = text.split()\n",
        "tags = [\"B_person\", \"I_person\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B_location\", \"I_location\"]\n",
        "print(list(zip(tokens, tags)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqC8uwyEZRZP",
        "outputId": "3efb3bb4-d8ec-42ee-a561-ef66e7cc9e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Joe', 'B_person'), ('Biden', 'I_person'), ('is', 'O'), ('the', 'O'), ('president', 'O'), ('of', 'O'), ('the', 'O'), ('United', 'B_location'), ('States', 'I_location')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def named_entity_extractor(tokens, tags):\n",
        "  named_entities = []\n",
        "  named_entity, entity_type = None, None\n",
        "  for token, tag in zip(tokens, tags):\n",
        "    if tag == \"\":\n",
        "      named_entity = token\n",
        "      entity_type = tag.split('_')[1]\n",
        "    elif tag == \"O\":\n",
        "      if named_entity is not None:\n",
        "        named_entities.append((named_entity, entity_type))\n",
        "        named_entity, entity_type = None, None\n",
        "    elif tag.startswith(\"B\"):\n",
        "      if named_entity is not None:\n",
        "        named_entities.append((named_entity, entity_type))\n",
        "      named_entity = token\n",
        "      entity_type = tag.split('_')[1]\n",
        "    elif tag.startswith(\"I\"):\n",
        "      assert tag.split('_')[1] == entity_type\n",
        "      named_entity = f\"{named_entity} {token}\"\n",
        "  if named_entity is not None:\n",
        "    named_entities.append((named_entity, entity_type))\n",
        "  return named_entities\n",
        "\n",
        "assert named_entity_extractor(tokens, tags) == [('Joe Biden', 'person'), ('United States', 'location')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3Ec1hpmaM8X",
        "outputId": "69bd2d35-b4cd-4fa3-b423-4011ea610cc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Joe Biden', 'person'), ('United States', 'location')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XuY0Ob3KdbC2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}