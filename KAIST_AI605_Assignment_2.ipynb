{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KAIST AI605 Assignment 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63327dc9f32f4be08d451b8803173401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_542394e60d0c4148a398cd2a0eadf1ce",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aadb059f904f4f37b0c90c40788e26d3",
              "IPY_MODEL_1816cc4aac3a43d8a8c1d5f208d51861",
              "IPY_MODEL_29778d34ff7a4712b1019c7148f21443"
            ]
          }
        },
        "542394e60d0c4148a398cd2a0eadf1ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aadb059f904f4f37b0c90c40788e26d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0493d08624d94ce5854fd3f992e39b54",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6fd2629d732e4f57afca221b92ac6e02"
          }
        },
        "1816cc4aac3a43d8a8c1d5f208d51861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4a4da29728d54b1f8db9c927642f865e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b50cb9c9ff0a48e8846eb13333b7a224"
          }
        },
        "29778d34ff7a4712b1019c7148f21443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_421fa1aa714c49a6a7bfc0991fb18b42",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:00&lt;00:00, 47.44it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ff1d38f0c3f463bacdf3797ac125372"
          }
        },
        "0493d08624d94ce5854fd3f992e39b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6fd2629d732e4f57afca221b92ac6e02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a4da29728d54b1f8db9c927642f865e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b50cb9c9ff0a48e8846eb13333b7a224": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "421fa1aa714c49a6a7bfc0991fb18b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ff1d38f0c3f463bacdf3797ac125372": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbGnNWI1lRy_"
      },
      "source": [
        "# KAIST AI605 Assignment 2: Retrieval\n",
        "TA in charge: Miyoung Ko (miyoungko@kaist.ac.kr)\n",
        "\n",
        "**Due Date:** Apr 26 (Tue) 11:00pm, 2022\n",
        "\n",
        "## Your Submission\n",
        "If you are a KAIST student, you will submit your assignment via [KLMS](https://klms.kaist.ac.kr). If you are a NAVER student, you will submit via [Google Form](https://forms.gle/FSng5HUwtQinTFAU8). \n",
        "\n",
        "You need to submit both (1) a PDF of this notebook, and (2) a link to CoLab for execution (.ipynb file is also allowed).\n",
        "\n",
        "Use in-line LaTeX (see below) for mathematical expressions. Collaboration among students is allowed but it is not a group assignment so make sure your answer and code are your own. Make sure to mention your collaborators in your assignment with their names and their student ids.\n",
        "\n",
        "## Grading\n",
        "The entire assignment is out of 20 points. You can obtain up to 2 bonus points (i.e. max score is 22 points). For every late day, your grade will be deducted by 2 points (KAIST students only). You can use one of your no-penalty late days (7 days in total). Make sure to mention this in your submission. You will receive a grade of zero if you submit after 7 days.\n",
        "\n",
        "\n",
        "## Environment\n",
        "You will need Python 3.7+ and PyTorch 1.9+, which are already available on Colab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYxEp1XMpxem",
        "outputId": "f6acf509-3e82-4c9e-8daf-f11f1034ecce"
      },
      "source": [
        "from platform import python_version\n",
        "import torch\n",
        "\n",
        "print(\"python\", python_version())\n",
        "print(\"torch\", torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python 3.7.12\n",
            "torch 1.9.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eut41a9MCyAI"
      },
      "source": [
        "You will use SQuAD, a classic machine reading comprehension dataset, in this assignment. Note that while this is an MRC dataset, we will also use it for retrieval by trying to find the correct document corresponding to the question among all the documents in the **validation** data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4Dzd3zoDSKR"
      },
      "source": [
        "!pip install -q datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338,
          "referenced_widgets": [
            "63327dc9f32f4be08d451b8803173401",
            "542394e60d0c4148a398cd2a0eadf1ce",
            "aadb059f904f4f37b0c90c40788e26d3",
            "1816cc4aac3a43d8a8c1d5f208d51861",
            "29778d34ff7a4712b1019c7148f21443",
            "0493d08624d94ce5854fd3f992e39b54",
            "6fd2629d732e4f57afca221b92ac6e02",
            "4a4da29728d54b1f8db9c927642f865e",
            "b50cb9c9ff0a48e8846eb13333b7a224",
            "421fa1aa714c49a6a7bfc0991fb18b42",
            "5ff1d38f0c3f463bacdf3797ac125372"
          ]
        },
        "id": "72hC4Q8fDf7W",
        "outputId": "538114b8-6586-4e83-b342-669fd00758d3"
      },
      "source": [
        "from datasets import load_dataset\n",
        "from pprint import pprint\n",
        "\n",
        "squad_dataset = load_dataset('squad')\n",
        "pprint(squad_dataset['train'][0]) # 'context' contains the document"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63327dc9f32f4be08d451b8803173401",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'answers': {'answer_start': [515], 'text': ['Saint Bernadette Soubirous']},\n",
            " 'context': 'Architecturally, the school has a Catholic character. Atop the '\n",
            "            \"Main Building's gold dome is a golden statue of the Virgin Mary. \"\n",
            "            'Immediately in front of the Main Building and facing it, is a '\n",
            "            'copper statue of Christ with arms upraised with the legend '\n",
            "            '\"Venite Ad Me Omnes\". Next to the Main Building is the Basilica '\n",
            "            'of the Sacred Heart. Immediately behind the basilica is the '\n",
            "            'Grotto, a Marian place of prayer and reflection. It is a replica '\n",
            "            'of the grotto at Lourdes, France where the Virgin Mary reputedly '\n",
            "            'appeared to Saint Bernadette Soubirous in 1858. At the end of the '\n",
            "            'main drive (and in a direct line that connects through 3 statues '\n",
            "            'and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
            " 'id': '5733be284776f41900661182',\n",
            " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes '\n",
            "             'France?',\n",
            " 'title': 'University_of_Notre_Dame'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB7xyzIgnnkA"
      },
      "source": [
        "## 1. Measuring Similarity\n",
        "We discussed in Lecture 04 that there are several ways to measure similarity between two vectors, such as L2 (Euclidean) distance, L1 (Manhattan) distance, inner product, and cosine distance. Here, only L1 and L2 (and angular distance) are *metric* (see *Definition* at https://en.wikipedia.org/wiki/Metric_(mathematics))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_LOyd1iOKsG"
      },
      "source": [
        "> **Problem 1.1** *(2 points)* Using the definition of metric above, prove that L1 distance is a metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yND_V75w94Pd"
      },
      "source": [
        "> **Problem 1.2** *(2 points)* Prove that negative inner product is NOT a metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFcaA8GI-B7X"
      },
      "source": [
        "> **Problem 1.3** *(2 points)* Prove that cosine distance (1 - cosine similarity) is NOT a metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfSr80bq-Gr6"
      },
      "source": [
        "> **Problem 1.4 (bonus)** *(2 points)* Given a model that can perform nearest neighbor search in L2 space, can you modify your query and your key vectors to perform maximum inner product search? (Hint: Recall the difference between MIPS and L2 NNS in Lecture 04. Can you modify key vectors so that the difference becomes 0?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F1E-W04Bxow"
      },
      "source": [
        "## 2. Sparse Search\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr94hZkt-dc9"
      },
      "source": [
        "We first create an abstract class for performing similarity search as follows (`raise NotImplementedError()` means you have to override these methods when you subclass the class):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iXGXr7i-8MD"
      },
      "source": [
        "class SimilaritySearch(object):\n",
        "  def __init__(self):\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  def train(self, documents: list):\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  #Add documents (a list of text)\n",
        "  def add(self, documents: list):\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  #Returns the indices of top-k documents among the added documents\n",
        "  #that are most similar to the input query \n",
        "  def search(self, query: str, k: int) -> list:\n",
        "    raise NotImplementedError()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryvHK75tE5JO"
      },
      "source": [
        "You will use the same space-based tokenizer that you used in Assignment 1, with lowercasing to make it case insensitive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cjdOzOaBt0k"
      },
      "source": [
        "> **Problem 2.1** *(2 points)* We will first start with Bag of Words that we discussed in Lecture 08. Using the definition in the class (don't worry about the exact definition though), implement `BagOfWords` class that subclasses `SimilaritySearch` class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVbZm1HhCeQh"
      },
      "source": [
        "> **Problem 2.2** *(2 points)* Using the definition in Lecture 08 (don't worry about the exact definition though), implement `TFIDF` class that subclasses `BagOfWords` class. Use natural log (instead of log with base 10)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw_uPvvIEPbk"
      },
      "source": [
        "> **Problem 2.3** *(2 points)* Use `TFIDF` to masure the recall rate of the correct document when 10 documents (contexts) are retrieved (this is called **Recall@10**) in SQuAD **validation** set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E78UAz3HEyfZ"
      },
      "source": [
        "## 3. Dense Search\n",
        "\n",
        "To obtain the embedding of each document and query, you will use pretrained word embeddings. Recall that most word embeddings are trained in a self-supervised way from a large text corpus. Here, we will use BERT word embeddings, which are also self-supervised. You will compute the document's embedding by simply averaging the embeddings of all words in the document (same for the query), and then normalizing it. This way, inner product effectively becomes cosine similarity."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT word embeddings can be easily obtained by using `transformers` library by Hugging Face. First, install the library: "
      ],
      "metadata": {
        "id": "LwyDBjMgatJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM_oMJSja5L_",
        "outputId": "4bfdf2d3-f968-4a17-ddb4-c205b863e779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.0 MB 14.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 58.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 8.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 69.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 65.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will then download the necessary tokenizer and the model."
      ],
      "metadata": {
        "id": "hGZPS3WE0Ttl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Glhu7-t6vqLE",
        "outputId": "7a815aaf-1518-4209-8aca-f7ee9aa100b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the tokenizer behaves a little differently from what you have done so far. It is a subword tokenizer and it inserts special tokens at the first and at the last, which should be ignored when you are computing the average."
      ],
      "metadata": {
        "id": "ROn70Wnm0YO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello KAIST!\"\n",
        "tokens = tokenizer.tokenize(text)\n",
        "input_ = tokenizer(text)\n",
        "input_tensor = tokenizer(text, return_tensors='pt')\n",
        "\n",
        "print(tokens) # ['hello', 'kai', '##st', '!'] Note that (1) ## indicates subword, and (2) all characters are lowercased.\n",
        "print(input_['input_ids']) # [101, 7592, 11928, 3367, 999, 102], where the first and the last tokens are special tokens\n",
        "print(input_tensor['input_ids']) # same as line 7 but in PyTorch tensor\n",
        "print(tokenizer.convert_ids_to_tokens(input_['input_ids'])) # you will verify that the first and the last tokens are special tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYhsgttYxqcL",
        "outputId": "0433dc19-f810-4799-f062-1c77a0f0d22b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'kai', '##st', '!']\n",
            "[101, 7592, 11928, 3367, 999, 102]\n",
            "tensor([[  101,  7592, 11928,  3367,   999,   102]])\n",
            "['[CLS]', 'hello', 'kai', '##st', '!', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model contains not only the word embeddings but also the BERT model parameters. Here, you will only use embeddings (you will use the full model in Assignment 4)."
      ],
      "metadata": {
        "id": "g125lKkG1EoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.embeddings(input_tensor['input_ids'])\n",
        "print(output.size()) # [1, 6, 768], where the first dim is batch size, second dim is number of tokens, and third is hidden size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4AMvZnfy466",
        "outputId": "8ba85064-4998-4caa-edac-7bba707799f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj5wg32wGEd6"
      },
      "source": [
        "> **Problem 3.1** *(2 points)* Implement `BERTEmbeddingSearch` class that subclasses `SimilaritySearch` class, using PyTorch's tensor native operation for the dense search. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE9PJg8AGbYV"
      },
      "source": [
        "> **Problem 3.2** *(2 points)* Use `BERTEmbeddingSearch` to measure the recall at 10 for SQuAD validation dataset. How does it compare to TFIDF?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MpUySZMGqUc"
      },
      "source": [
        "> **Problem 3.3** *(2 points)* Implement `BERTEmbeddingFaiss` that subclasses `SimilaritySearch` and uses Faiss `IndexFlatIP` instead of PyTorch native tensor operation for search. Refer to the Faiss wiki (https://github.com/facebookresearch/faiss/wiki/Getting-started) for instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CJT5YnlHU29"
      },
      "source": [
        "> **Problem 3.4** *(2 points)* Compare the speed between `BERTEmbeddingSearch` and `BERTEmbeddingFaiss` on SQuAD. To make the measurement accurate, perform search many times (at least more than 1000) and take the average."
      ]
    }
  ]
}