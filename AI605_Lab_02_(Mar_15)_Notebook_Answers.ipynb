{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI605 Lab 02 (Mar 15) Notebook Answers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Quiz 02 Answers\n",
        "1. False. They are not equivalent; arg min of them are equivalent.\n",
        "2. [1.0, 0.0]\n",
        "3. False. No activation function.\n",
        "4. True.\n",
        "5. False. truncate if the input is longer, and pad if the input is shorter.\n",
        "6. False. Sigmoid also gives non-linearity. Tanh was preferred due to its sign (sigmoid is always positive). "
      ],
      "metadata": {
        "id": "BcqkrmEFHQ-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab 02 Objectives"
      ],
      "metadata": {
        "id": "5_JnAIYaIJV-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSU37NhzAEhp"
      },
      "outputs": [],
      "source": [
        "# Objective 1: Computationally verify that NLL is equivalent to cross entropy of one-hot label\n",
        "\n",
        "import torch\n",
        "from torch.nn import CrossEntropyLoss, Softmax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = torch.tensor([1]) # note that target for cel should contain the labels, not the one_hot\n",
        "input_ = torch.tensor([[0.1, 0.9]]) # note that input_ should be logits before softmax for CrossEntropyLoss\n",
        "cel = CrossEntropyLoss()\n",
        "softmax = Softmax(dim=1)\n",
        "out1 = cel(input_, target)\n",
        "out2 = -softmax(input_)[0, 1].log() # your code goes here\n",
        "\n",
        "print(out1, out2)\n",
        "assert (out1-out2).abs() < 0.0001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_04sxZfAR-4",
        "outputId": "9b371ccf-1d3e-448e-c040-bdf61bd9556a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.3711) tensor(0.3711)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Objective 2: Use a space tokenizer to create a vocab from a text list and map each text to vocab ids\n",
        "text_list = [\"Hello world\", \"Hi world\", \"Hello cute puppy\"]\n",
        "vocab = ['<UNK>'] + sorted(set(word for text in text_list for word in text.split()))\n",
        "token2idx = {word: id for id, word in enumerate(vocab)}\n",
        "\n",
        "def text2ids(text):\n",
        "  tokens = text.split()\n",
        "  ids = tuple(token2idx[token] if token in token2idx else 0 for token in tokens) # your code goes here\n",
        "  return ids\n",
        "\n",
        "print(vocab)\n",
        "assert text2ids(text_list[0]) == (1, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbz2jSJkAh3u",
        "outputId": "2e1be4e3-7db1-41bd-b739-ace73e76213a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<UNK>', 'Hello', 'Hi', 'cute', 'puppy', 'world']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Objective 3: Verify that a linear layer on top of the one-hot vectors is equivalent to PyTorch nn.Embedding\n",
        "import torch\n",
        "from torch.nn.functional import one_hot\n",
        "\n",
        "labels = torch.tensor([1])\n",
        "one_hot_labels = one_hot(labels, num_classes=3)\n",
        "print(labels, one_hot_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3sLsLqaEqMC",
        "outputId": "08cc41c3-da41-4567-8964-22b4a98960b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1]) tensor([[0, 1, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Embedding\n",
        "embedding = Embedding(3, 4)\n",
        "emb1 = embedding(labels)\n",
        "emb2 = one_hot_labels.float() @ embedding.weight # your code goes here\n",
        "print(emb1, emb2)\n",
        "assert (emb1-emb2).abs().sum() < 0.0001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWN_-_yEGIda",
        "outputId": "dc2dcb5a-4283-42cb-88e4-d977daaa7985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0988,  1.0179,  0.5809, -0.7040]], grad_fn=<EmbeddingBackward0>) tensor([[ 0.0988,  1.0179,  0.5809, -0.7040]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Objective 4: Create a simple recurrent neural network with tanh activation\n",
        "import torch\n",
        "from torch.nn import Linear, Tanh\n",
        "torch.manual_seed(605)\n",
        "batch_size = 3\n",
        "hidden_size = input_size = 4\n",
        "\n",
        "layer = Linear(hidden_size + input_size, hidden_size) # your code goes here\n",
        "activation = Tanh()\n",
        "\n",
        "h_prev = torch.randn([batch_size, hidden_size])\n",
        "x_cur = torch.randn([batch_size, hidden_size])\n",
        "h_cur = activation(layer(torch.cat([h_prev, x_cur], dim=1)))\n",
        "assert h_cur.size() == (batch_size, hidden_size)"
      ],
      "metadata": {
        "id": "rZDWYoYAGW2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ApWVym33JFLD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}